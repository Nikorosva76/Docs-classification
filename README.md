# Docs-classification
Классификация актов выполненных работ

## Цель проекта: 
автоматизировать обработку актов выполненных работ: сортировать входящие акты выполненных рабо по типам (всего около 10-ти видов актов). 

## Краткое описание задачи: 
Организация оказывает услуги в сфере b-to-b. По результатам выполнения каждого отдельного вида работ составляется акт соответствующего типа. Часть сведений в акте заполняется вручную, часть - типографским способом.  Всего за месяц кол-во составленных актов каждого типа превышает несколько тыс. единиц. Все документы сканируются "пакетами" (.pdf). В "пакет" может входить несколько актов разного типа, а также вспомогательные документы (фото, справки, пояснения и т.п.) Т.о. необходимо: 
- разобрать "пакет" на составляющие части (виды актов и доп. документы).
- разложить акты по соответствующим дирректориям архива
- заполнить служебную базу данных сведениями из акта (вид акта, дата, номер, номер задания и т.п.).

## Некоторая специфика
Исходные документы (акты и приложения) заполняются сотрудниками в полевых условиях. Далее сотрудники приносят пачки документов в офис и сканируют их в "pdf-пакеты". В результате в состав "пакета" могут попасть перевернутые изображения, грязные изображения. Часть актов имеют альбомный формат, часть - книжный. Сканеры в организации имеют разный износ и качество сканирования. В результате ширина полей (отступов) в сканах "плавает". Яркость изображения плавает. Сканы имеют наклон от нормальной ориентации. Всё это привносит дополнительные трудности. 

## Краткое описание представленного кода
В текущем репозитории представлены три модуля:

### Генератор обучающего датасета:
Модуль содержит код для автоматизации формирования обучающих и тестовых образцов - маски типа документа: "01Т", "05В" и т.п.
Модуль является вспомогательным. В ходе подготовки обучающего датасета из отобранных образцов оригинальных актов "вырезается" образец изображения, который содержит маску-идентификатор типа акта:
![oc03095520220603150058_2_cor_0 png_02B_0 98_113_719](https://user-images.githubusercontent.com/101862550/184609319-4cd4634c-6821-43c8-9c22-f071d82ea2d5.png)
![oc03069220220602150035_002_0_cor_0 png_05T_1 0_183_771](https://user-images.githubusercontent.com/101862550/184609446-88cb01ce-576e-49de-ac12-c807cb00a7c5.png)
![oc03069220220602150035_009_0_cor_90 png_01T_0 97_181_917](https://user-images.githubusercontent.com/101862550/184609494-93203e19-7bac-4156-b0c1-d077f3f6d192.png)




### Обучение модели:
Модуль включает в себя:
- код формирования обучающего, валидационного и тестового датасетов
- код формирующий, обучающий и записывающий модели
- код тестирования модели


### Главный распознающий модуль, который выполняет следующие операции:
- разбиение "pdf-пакетов" на составляющие.
- корректировка изображения: приведение актов к "нормальному" книжному или альбомному формату. Т.е. акты, которые имеют изначально книжную ориентацию, приводятся к "книжной" ориентации. "Альбомные", соответсвенно к "альбомной". Перевернутые сканы поворачиваются в нужную сторону.

    *Примечание 1: в более ранних версиях сканы предварительно подвергались "выпрямлению". Однако, в последствии удовлетворительные результаты распознавания были   получены на "кривых" сканах и от выпрямления стало возможным отказаться.*
 
- классификация актов по типам и размещение сканов в соответствующие папки архива: "01Т", "01В" и т.п.

    *Примечание 2: поскольку проект реализуется в действующей организации, то по соображениям коммерческой тайны представлена только часть рабочего кода. Исходный датасет, естественно, __не представлен__ также по соображениям защиты коммерческой тайны.*

## Основная функция распознавания реализована посредством 12 - слойной нейронки keras:

 В составе нейронки входят следующие слои: conc2d, max_pooling_2d, dropout, flatten, dense.
 Нейронка обрабатывет около 2,4 млн. параметров. Обучение на офисном ноутбуке занимает около 5-и минут. 
 В более ранних версиях, были использованы более простые нейронки (5-6 слоев), но они давали неприемлемое кол-во FP - прогнозов.
 
## Полученные результаты
Принимая во внимание задачу проекта и специфику бизнес-процесса, скорость имеет второстепенное значение, т.к. обработка документов происходит "в ночную смену". В приоритете стоит задача достижения максимальной точности. 

Все прогнозы условно можно разбить следующим образом:
- TP - когда модель с вероятностью не менее 95% распознаёт реальный класс документа (тип акта).
- FP - когда модель "путает" виды актов и/или классифицирует вспомогательный документ из пакета как акт некоторого типа.
- TN - когда модель с вероятностью не менее 95% относит некий документ, не акт, из "pdf-пакета" к классу __"unknown"__. Т.е. если в пакете есть фото, пояснительные таблички и т.п. вспомогательные документы, то модель должна идентифицировать их как неизвестный и поместить в соответсвующую папку.
- FN - когда модель не распознаёт некоторый акт и относит его к классу __"unknown"__.

Т.о. в нашем случае, задача повышения точности выражается в том, чтобы во-первых, минимизировать FP-прогнозы, и во-вторых, максимизировать TP-прогнозы. 
Минимум FP-прогнозов более важен, потому что если некий акт будет помещен __не в "свою" папку__, то потом найти такого рода ошибку труднее, чем если бы акт просто был классифицирован как __"unknown"__. Это связано с тем, что папку __"unknown"__ потом разбирают вручную и если там находится некоторый реальный акт, то вясняется почему это произошло. Зачастую это обусловленно низким качеством скана: грязный, кривой, "почирканый".

Задача повышения точности эффективно решается путем увеличения обучающего датасета и кол-вом эпох обучения. В результате даже вот такие "зашумленные" образцы !
![01T_b_9_3](https://user-images.githubusercontent.com/101862550/184613545-fb11cbfe-33b0-453d-ab7a-ab3ebc200d39.png)
 прогнозирубтся с вероятностью не менее 97%. 

Задача минимизации FN-прогнозов сильно связана с особенностями формирования "pdf-пакетов" и качеством сканирования. Суть в следубщем: если скан акта  сделан таким образом, что маска акта не попадает в "зону-поиска", то акт будет отнесен к классу __"unknown"__. Чтобы минимизировать такие случаи, надо расширять зону-поиска, но это увеличивает время обработки. Реже встречаются случаи, когда в обучающий датасет добавляется новый образец и модель переучиватеся.


## Использованные библиотеки
numpy, pandas, matplotlib, PIL, os, fitz, keras
